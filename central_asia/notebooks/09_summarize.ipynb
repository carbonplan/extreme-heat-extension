{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 09: Create compiled datasets and summary statistics\n",
    "*Compile datasets from different GCMs and create summary statistics (e.g., annual maxima, days over threshold).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import coiled\n",
    "import dask\n",
    "import xarray as xr\n",
    "from utils import gcm_list, load_multimodel_results, summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Set up cluster to handle multiprocessing using a Dask client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster = coiled.Cluster(\n",
    "    n_workers=2,\n",
    "    name=\"09\",\n",
    "    worker_vm_types=[\"m7g.medium\"],\n",
    "    scheduler_vm_types=[\"m7g.medium\"],\n",
    "    region=\"us-west-2\",\n",
    "    spot_policy=\"spot_with_fallback\",\n",
    ")\n",
    "\n",
    "cluster.adapt(minimum=1, maximum=100)\n",
    "\n",
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Compile all individual GCM datasets into one multimodel dataset that is optimally chunked for timeseries analysis. Create summaries for each analysis period and multimodel medians of those summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rename_dict = {\"wbgt-shade\": \"scen\", \"wbgt-sun\": \"WBGT-sun\"}\n",
    "analysis_period = {\n",
    "    \"historical\": slice(\"1985\", \"2014\"),\n",
    "    \"ssp245-2030\": slice(\"2020\", \"2039\"),\n",
    "    \"ssp245-2050\": slice(\"2040\", \"2059\"),\n",
    "    \"ssp245-2070\": slice(\"2060\", \"2079\"),\n",
    "    \"ssp245-2080\": slice(\"2070\", \"2089\"),\n",
    "    \"ssp245-2090\": slice(\"2080\", \"2099\"),\n",
    "    \"ssp370-2030\": slice(\"2020\", \"2039\"),\n",
    "    \"ssp370-2050\": slice(\"2040\", \"2059\"),\n",
    "    \"ssp370-2070\": slice(\"2060\", \"2079\"),\n",
    "    \"ssp370-2080\": slice(\"2070\", \"2089\"),\n",
    "    \"ssp370-2090\": slice(\"2080\", \"2099\"),\n",
    "}\n",
    "\n",
    "scenarios = [\"ssp245\", \"ssp370\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for metric in [\"wbgt-sun\", \"wbgt-shade\"]:\n",
    "    full_ds = load_multimodel_results(gcm_list[0:1], scenarios, metric)\n",
    "    full_ds = full_ds.chunk({\"time\": -1, \"processing_id\": 850, \"gcm\": -1})\n",
    "    full_ds = full_ds.rename({rename_dict[metric]: metric})\n",
    "    for scenario, timeframe in analysis_period.items():\n",
    "        print(scenario, timeframe)\n",
    "        compiled_store = (\n",
    "            \"s3://carbonplan-scratch/extreme-heat-extension/v1.1/\"\n",
    "            + f'outputs/zarr/daily/{scenario}-WBGT-{metric.split(\"-\")[1]}.zarr'\n",
    "        )\n",
    "        full_ds.sortby(\"time\").sel(time=timeframe).to_zarr(\n",
    "            compiled_store, mode=\"w\", zarr_format=2, consolidated=True\n",
    "        )\n",
    "        # 1 gcm ~ 4 mins on 1 worker to this point\n",
    "        ds = xr.open_zarr(compiled_store)\n",
    "        summarized = summarize(ds[metric], metric.split(\"-\")[0]).load()\n",
    "\n",
    "        annual_medians = summarized.sel(year=timeframe).median(dim=\"year\")\n",
    "        ensemble_median = annual_medians.median(dim=\"gcm\")\n",
    "        results = xr.concat(\n",
    "            [\n",
    "                annual_medians,\n",
    "                ensemble_median.expand_dims(dim={\"gcm\": [\"multimodel_median\"]}),\n",
    "            ],\n",
    "            dim=\"gcm\",\n",
    "        ).load()\n",
    "        summary_store = (\n",
    "            \"s3://carbonplan-scratch/extreme-heat/v1.1/outputs/\"\n",
    "            + f'zarr/summaries/{scenario}-summaries-WBGT-{metric.split(\"-\")[1]}.zarr'\n",
    "        )\n",
    "        print(summary_store)\n",
    "        results = dask.optimize(results)[0]\n",
    "        results.to_zarr(summary_store, mode=\"w\", zarr_format=2, consolidated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
