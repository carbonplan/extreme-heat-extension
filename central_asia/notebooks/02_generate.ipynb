{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 02: Generate gridded WBGT in the shade estimates\n",
    "*Use downscaled CMIP6 projections from the [NEX-GDDP-CMIP6 dataset](https://www.nccs.nasa.gov/services/data-collections/land-based-products/nex-gddp-cmip6) to generate gridded estimates of WBGT. The projections cover historical and future (SSP2-4.5) periods at a daily timestep and 0.25 degree resolution for the entire globe's land surface.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import coiled\n",
    "import dask\n",
    "import numpy as np\n",
    "import thermofeel as tf\n",
    "import xarray as xr\n",
    "import xclim\n",
    "from tqdm import tqdm\n",
    "from utils import gcm_list, load_virtual_nasa_nex, wbgt\n",
    "\n",
    "os.environ[\"USE_PYGEOS\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_pressure(temperature, elevation):\n",
    "    \"\"\"\n",
    "    Approximate surface pressure given the elevation and temperature.\n",
    "    Method from https://doi.org/10.1038/s41598-019-50047-w\n",
    "    \"\"\"\n",
    "    return 101325 * np.power(10, -elevation / (18400 * temperature / 273.15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Set up cluster to handle multiprocessing using a Dask client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cluster = coiled.Cluster(n_workers=3, worker_memory=\"64 GiB\")\n",
    "cluster = coiled.Cluster(\n",
    "    n_workers=50,\n",
    "    worker_vm_types=[\"m8g.large\"],\n",
    "    scheduler_vm_types=[\"m8g.4xlarge\"],\n",
    "    region=\"us-west-2\",\n",
    "    spot_policy=\"spot_with_fallback\",\n",
    ")\n",
    "\n",
    "\n",
    "cluster.adapt(minimum=50, maximum=200)\n",
    "\n",
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Read in elevation data, which was processed in `01_elevation.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "elev = xr.open_zarr(\n",
    "    \"s3://carbonplan-climate-impacts/extreme-heat/v1.0/inputs/elevation.zarr\"\n",
    ")\n",
    "elev = elev.chunk({\"lat\": -1, \"lon\": -1}).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Identify which scenarios and years to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = [\"historical\", \"ssp245\", \"ssp370\"]\n",
    "\n",
    "\n",
    "def build_parameters() -> list:\n",
    "\n",
    "    param_list = []\n",
    "    for gcm in gcm_list:\n",
    "        for scenario in scenarios:\n",
    "            param_list.append((gcm, scenario))\n",
    "    return param_list\n",
    "\n",
    "\n",
    "param_tuples = build_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Calculate future projections of WBGT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(param_tuple: tuple):\n",
    "\n",
    "    elev = xr.open_zarr(\n",
    "        \"s3://carbonplan-climate-impacts/extreme-heat/v1.0/inputs/elevation.zarr\"\n",
    "    )\n",
    "    elev = elev.chunk({\"lat\": -1, \"lon\": -1}).compute()\n",
    "\n",
    "    variables = [\"tasmax\", \"huss\", \"tas\"]\n",
    "\n",
    "    gcm, scenario = param_tuple\n",
    "\n",
    "    id_string = f\"{gcm}-{scenario}\"\n",
    "    output = (\n",
    "        f\"s3://carbonplan-scratch/extreme-heat/wbgt-shade-\"\n",
    "        f\"gridded/years/{gcm}/{id_string}.zarr\"\n",
    "    )\n",
    "\n",
    "    ds = load_virtual_nasa_nex(gcm=gcm, scenario=scenario)[variables]\n",
    "    ds = ds.chunk({\"time\": 15})\n",
    "\n",
    "    # # calculate elevation-adjusted pressure\n",
    "    ds[\"ps\"] = xr.apply_ufunc(adjust_pressure, ds[\"tas\"], elev, dask=\"allowed\").rename(\n",
    "        {\"elevation\": \"ps\"}\n",
    "    )[\"ps\"]\n",
    "    ds[\"ps\"].attrs[\"units\"] = \"Pa\"\n",
    "    ds[\"hurs\"] = xclim.indices.relative_humidity(\n",
    "        tas=ds[\"tasmax\"], huss=ds[\"huss\"], ps=ds[\"ps\"]\n",
    "    )\n",
    "    ds[\"tasmax\"].attrs = {}\n",
    "\n",
    "    # windspeed assumption of 0.5 m/s (approximating shaded/indoor\n",
    "    # conditions)\n",
    "    ds[\"sfcWind\"] = (ds[\"tas\"] - ds[\"tas\"]) + 0.5\n",
    "    ds[\"WBT\"] = tf.thermofeel.calculate_wbt(ds[\"tasmax\"] - 273.15, ds[\"hurs\"])\n",
    "\n",
    "    ds[\"BGT\"] = tf.thermofeel.calculate_bgt(ds[\"tasmax\"], ds[\"tasmax\"], ds[\"sfcWind\"])\n",
    "    ds[\"WBGT\"] = wbgt(ds[\"WBT\"], ds[\"BGT\"], ds[\"tasmax\"] - 273.15)\n",
    "    ds[\"WBGT\"].attrs[\"units\"] = \"degC\"\n",
    "    ds = ds[[\"WBGT\"]]\n",
    "    ds = dask.optimize(ds)[0]\n",
    "    t = ds.to_zarr(output, consolidated=True, mode=\"w\", compute=False)\n",
    "    t.compute()\n",
    "    return output\n",
    "\n",
    "\n",
    "for input_params in tqdm(param_tuples):\n",
    "\n",
    "    process(param_tuple=input_params)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
